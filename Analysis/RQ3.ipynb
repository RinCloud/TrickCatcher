{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ3: Ablation study\n",
    "\n",
    "Here we comes to the RQ3.\n",
    "\n",
    "Most of the used middle data has been introduced in RQ1. Please first read the `RQ1.ipynb` before readinig this notebook.\n",
    "\n",
    "First load the oracles and validities of the generated test inupts of TrickyBugs (C++)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_direct=pd.read_pickle(\"../Data/ref_direct.pkl\")\n",
    "ref_generator=pd.read_pickle(\"../Data/ref_generator.pkl\")\n",
    "input_valid_direct=pd.read_pickle(\"../Data/input_valid_direct.pkl\")\n",
    "input_valid_generator=pd.read_pickle(\"../Data/input_valid_generator.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern 1 (`DPP`) and Pattern 6 (`TC`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern 1 is actually the result of `DPP`.\n",
    "\n",
    "Pattern 6 is actually the result of `TC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpp_results={}\n",
    "tc_results={}\n",
    "for i in range(2,11):\n",
    "    dpp_results[i]=pd.read_pickle(\"../Data/dpp_results_\"+str(i)+\".pkl\")\n",
    "    tc_results[i]=pd.read_pickle(\"../Data/tc_results_\"+str(i)+\".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern 1 results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=2:   0.20956623711371966 0.2636987240299441 0.23353661844350743\n",
      "k=3:   0.20396645390996487 0.29021802532171725 0.23956536060239783\n",
      "k=4:   0.19460538744282999 0.32221122325619306 0.24265489398798137\n",
      "k=5:   0.1852205203142131 0.3642672875412245 0.24557333417517072\n",
      "k=6:   0.17680501283089603 0.41599864490486327 0.24814504698223278\n",
      "k=7:   0.16945312103933516 0.4669620060512271 0.24866841143111093\n",
      "k=8:   0.1630807527206393 0.5309215052683013 0.24951814700323122\n",
      "k=9:   0.1577982893399422 0.5549010872975481 0.24572055258851463\n",
      "k=10:   0.1550393198448038 0.6080448325163399 0.2470785351177508\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,11):\n",
    "    print(f\"k={i}:   \",end=\"\")\n",
    "    len_PUT=251\n",
    "    recall=dpp_results[i]['TP_rate'].sum()/len_PUT\n",
    "    precision=dpp_results[i]['precision'].mean()\n",
    "    F1_score=2*precision*recall/(precision+recall)\n",
    "    print(recall,precision,F1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern 6 results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=2:   0.25064899043199457 0.6991469199396292 0.3690065786405434\n",
      "k=3:   0.26746132155212354 0.698565502120137 0.386820009153623\n",
      "k=4:   0.27743369969517 0.6969281770001491 0.3968779304517519\n",
      "k=5:   0.2831001070894958 0.6956268470073805 0.40242487255056225\n",
      "k=6:   0.2865356201045365 0.694509997111865 0.4056933728645398\n",
      "k=7:   0.289387750720712 0.6939485627652917 0.4084466543955757\n",
      "k=8:   0.29189056555686216 0.6934809094265741 0.410851217017039\n",
      "k=9:   0.2930941143958002 0.6940247425787345 0.41213794237168544\n",
      "k=10:   0.2937987576038061 0.6956932845146728 0.4131287852019906\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,11):\n",
    "    print(f\"k={i}:   \",end=\"\")\n",
    "    recall=tc_results[i]['TP_rate'].sum()/len_PUT\n",
    "    precision=tc_results[i]['precision'].mean()\n",
    "    F1_score=2*precision*recall/(precision+recall)\n",
    "    print(recall,precision,F1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern 2 uses the direct-generated program variants and direct-generated inputs of `DPP`. And it filters the program variants of `DPP` by base tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dpp_res=pd.read_pickle(\"../Data/dpp_res.pkl\")\n",
    "# df_dpp=dpp_res.merge(input_valid_direct,on=['pid','input_name'],how='left')\n",
    "# df_dpp['input_valid']=pd.to_numeric(df_dpp['input_valid'], errors='coerce').fillna(-1).astype(int)\n",
    "# df_dpp=(df_dpp\n",
    "# [~(    \n",
    "#     (df_dpp['out']=='TIME_OUT' )|\n",
    "#     (df_dpp['out']=='RUN_ERROR' )|\n",
    "#     (df_dpp['out']=='')\n",
    "# )\n",
    "# ])\n",
    "# df_dpp=pd.merge(df_dpp,ref_direct, on=['pid', 'input_name'], suffixes=('', '_ref'),how='left')\n",
    "# df_dpp['out_correct']= (df_dpp['out']==df_dpp['ref_out'])\n",
    "\n",
    "# dpp_progs_submit=pd.read_pickle(\"../Data/dpp_progs_submit.pkl\")\n",
    "# df_p2=df_dpp.merge(dpp_progs_submit,on=['pid','sol_name'],how='left')\n",
    "# df_p2=df_p2.loc[(df_p2['submit_res']=='AC') | pd.isna(df_p2['submit_res'])]\n",
    "# p2_trigger=utils.get_trigger_df(df_p2,'cpp','dfp') \n",
    "# p2_trigger['len_sol_names']=p2_trigger['sol_names'].apply(lambda x:len(x))\n",
    "# p2_trigger['final_valid']= ( (p2_trigger['input_valid'] == 1) & p2_trigger['input_valid_byref'] & p2_trigger['out_correct'] )\n",
    "# p2_trigger['total_sols_num']=p2_trigger['pid'].apply(lambda x:len(df_p2[df_p2['pid']==x].drop_duplicates(subset=['sol_name']))-1)\n",
    "# for i in range(10):\n",
    "#     column_name=f\"num{i}\"\n",
    "#     p2_trigger[column_name] = p2_trigger['sol_names'].apply(lambda x: 1 if column_name in [sol.split('_')[1] for sol in x] else 0)\n",
    "\n",
    "\n",
    "\n",
    "#  **WARNING**: The codes above in this block are time consuming. An alternative choice is to load the result directly\n",
    "p2_trigger=pd.read_pickle(\"../Data/p2_trigger.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern 2 Uses majority voting to decide the oracle. (The `dfp` parameter of `compute_res_df()` indicates majority voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2_results={}\n",
    "for i in range(2,11):\n",
    "    p2_results[i]=utils.compute_res_df(p2_trigger,i,'dfp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print Pattern 2 reuslts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern 2 all results:\n",
      "k=2:   0.19854715003241183 0.269957681598938 0.22881014107876632\n",
      "k=3:   0.19320475416634672 0.30061299581811757 0.23522791539216903\n",
      "k=4:   0.1852894411377487 0.34239400850381757 0.24045474432703723\n",
      "k=5:   0.17856268092344244 0.39754583043252134 0.24643569005737592\n",
      "k=6:   0.17280800020818377 0.4532689657595359 0.2502200457359606\n",
      "k=7:   0.16789967321154256 0.4757355007597291 0.2482022062897802\n",
      "k=8:   0.1644651466879036 0.5038329629866947 0.24798203365906493\n",
      "k=9:   0.1620609370592584 0.48610562729402107 0.2430817564545331\n",
      "k=10:   0.16125653561740674 0.4818498861901082 0.24164412202966623\n"
     ]
    }
   ],
   "source": [
    "print(\"Pattern 2 all results:\")\n",
    "for i in range(2,11):\n",
    "    print(f\"k={i}:   \",end=\"\")\n",
    "    recall=p2_results[i]['TP_rate'].sum()/len_PUT\n",
    "    precision=p2_results[i]['precision'].mean()\n",
    "    F1_score=2*precision*recall/(precision+recall)\n",
    "    print(recall,precision,F1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern 3 uses the direct-generated program variants and direct-generated inputs of `DPP`. And it filters the program variants of `DPP` by base tests.\n",
    "\n",
    "First load the raw results of the filtered programs' outputs `df_p3_raw`. Then compute the trigger data `p3_trigger`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_p3_raw=pd.read_pickle(\"../Data/df_p3_raw.pkl\")\n",
    "# df_p3=df_p3_raw.merge(input_valid_direct,on=['pid','input_name'],how='left')\n",
    "# df_p3['input_valid']=pd.to_numeric(df_p3['input_valid'], errors='coerce').fillna(-1).astype(int)\n",
    "# df_p3=(df_p3\n",
    "# [~(    \n",
    "#     (df_p3['out']=='TIME_OUT' )|\n",
    "#     (df_p3['out']=='RUN_ERROR' )|\n",
    "#     (df_p3['out']=='')\n",
    "# )\n",
    "# ])\n",
    "# df_p3=pd.merge(df_p3,ref_direct, on=['pid', 'input_name'], suffixes=('', '_ref'),how='left')\n",
    "# df_p3['out_correct']= (df_p3['out']==df_p3['ref_out'])\n",
    "# p3_trigger=utils.get_trigger_df(df_p3,'cpp','tc')\n",
    "# p3_trigger['len_sol_names']=p3_trigger['sol_names'].apply(lambda x:len(x))\n",
    "# p3_trigger['final_valid']= ( (p3_trigger['input_valid'] == 1) & p3_trigger['input_valid_byref'] & p3_trigger['out_correct'] )\n",
    "# p3_trigger['total_sols_num']=p3_trigger['pid'].apply(lambda x:len(df_p3[df_p3['pid']==x].drop_duplicates(subset=['sol_name']))-1)\n",
    "# for i in range(10):\n",
    "#     column_name=f\"num{i}\"\n",
    "#     p3_trigger[column_name] = p3_trigger['sol_names'].apply(lambda x: 1 if column_name in [sol.split('_')[1] for sol in x] else 0)\n",
    "\n",
    "\n",
    "#  **WARNING**: The codes above in this block are time consuming. An alternative choice is to load the result directly\n",
    "p3_trigger=pd.read_pickle(\"../Data/p3_trigger.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern 3 uses diversity-driven differential testing to decide the oracle. (The `tc` parameter of `compute_res_df()` indicates diversity-driven.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3_results={}\n",
    "for i in range(2,11):\n",
    "    p3_results[i]=utils.compute_res_df(p3_trigger,i,'tc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print Pattern 3 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern 3 all results:\n",
      "k=2:   0.2255184431548641 0.6021822258709669 0.3281456767064979\n",
      "k=3:   0.22337500606160263 0.5964587927815134 0.32502682041427394\n",
      "k=4:   0.2218151078936111 0.5922935327797487 0.3227570555437472\n",
      "k=5:   0.22115994809317174 0.5905441167168733 0.32180375055876004\n",
      "k=6:   0.22067458018696584 0.5892480811375365 0.3210975050836431\n",
      "k=7:   0.22030589241407808 0.5882636063397192 0.32056103765758615\n",
      "k=8:   0.21996453257869436 0.5873521029494924 0.32006433436088283\n",
      "k=9:   0.21958839366669888 0.5863477320249088 0.31951702498748646\n",
      "k=10:   0.2190990518885125 0.5850410853618792 0.3188049972406761\n"
     ]
    }
   ],
   "source": [
    "print(\"Pattern 3 all results:\")\n",
    "for i in range(2,11):\n",
    "    print(f\"k={i}:   \",end=\"\")\n",
    "    recall=p3_results[i]['TP_rate'].sum()/len_PUT\n",
    "    precision=p3_results[i]['precision'].mean()\n",
    "    F1_score=2*precision*recall/(precision+recall)\n",
    "    print(recall,precision,F1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern 4 uses the program variants of `TC` and the test inputs of `DPP`.\n",
    "\n",
    "First load the raw results of programs' outputs `df_p4_raw`. Then compute the trigger data `p4_trigger`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_p4_raw=pd.read_pickle(\"../Data/df_p4_raw.pkl\")\n",
    "# df_p4=df_p4_raw.merge(input_valid_direct,on=['pid','input_name'],how='left')\n",
    "# df_p4['input_valid']=pd.to_numeric(df_p4['input_valid'], errors='coerce').fillna(-1).astype(int)\n",
    "# df_p4=(df_p4\n",
    "# [~(    \n",
    "#     (df_p4['out']=='TIME_OUT' )|\n",
    "#     (df_p4['out']=='RUN_ERROR' )|\n",
    "#     (df_p4['out']=='')\n",
    "# )\n",
    "# ])\n",
    "# df_p4=pd.merge(df_p4,ref_direct, on=['pid', 'input_name'], suffixes=('', '_ref'),how='left')\n",
    "# df_p4['out_correct']= (df_p4['out']==df_p4['ref_out'])\n",
    "\n",
    "# tc_progs_submit=pd.read_pickle(\"../Data/tc_progs_submit.pkl\")\n",
    "# df_p4=df_p4.merge(tc_progs_submit,on=['pid','sol_name'],how='left')\n",
    "# df_p4=df_p4.loc[(df_p4['submit_res']=='AC') | pd.isna(df_p4['submit_res'])]\n",
    "\n",
    "# p4_trigger=utils.get_trigger_df(df_p4,'cpp','tc')\n",
    "# p4_trigger['len_sol_names']=p4_trigger['sol_names'].apply(lambda x:len(x))\n",
    "# p4_trigger['final_valid']= ( (p4_trigger['input_valid'] != 0) & p4_trigger['input_valid_byref'] & p4_trigger['out_correct'] )\n",
    "# p4_trigger['total_sols_num']=p4_trigger['pid'].apply(lambda x:len(df_p4[df_p4['pid']==x].drop_duplicates(subset=['sol_name']))-1)\n",
    "# for i in range(10):\n",
    "#     column_name=f\"num{i}\"\n",
    "#     p4_trigger[column_name] = p4_trigger['sol_names'].apply(lambda x: 1 if column_name in [sol.split('_')[1] for sol in x] else 0)\n",
    "\n",
    "\n",
    "#  **WARNING**: The codes above in this block are time consuming. An alternative choice is to load the result directly\n",
    "p4_trigger=pd.read_pickle(\"../Data/p4_trigger.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern 4 uses diversity-driven differential testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4_results={}\n",
    "for i in range(2,11):\n",
    "    p4_results[i]=utils.compute_res_df(p4_trigger,i,'tc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print Pattern 4 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern 4 all results:\n",
      "k=2:   0.2226979020164961 0.4812086861210294 0.30448405125689965\n",
      "k=3:   0.23211778504307512 0.4748249894276327 0.3118083352971887\n",
      "k=4:   0.23712649827246562 0.46991501614573805 0.3151987542230212\n",
      "k=5:   0.2399456818239553 0.46745353503495846 0.31711501656172053\n",
      "k=6:   0.2425303566024106 0.46650659961277874 0.31914277801657254\n",
      "k=7:   0.2442231796676604 0.46726865561384245 0.3207846701090946\n",
      "k=8:   0.24569663985335402 0.46818073184236253 0.3222694463182489\n",
      "k=9:   0.2461246608271153 0.4680097717242874 0.3225968139300571\n",
      "k=10:   0.24590919682805434 0.46760006366546697 0.32231440419760643\n"
     ]
    }
   ],
   "source": [
    "print(\"Pattern 4 all results:\")\n",
    "for i in range(2,11):\n",
    "    print(f\"k={i}:   \",end=\"\")\n",
    "    recall=p4_results[i]['TP_rate'].sum()/len_PUT\n",
    "    precision=p4_results[i]['precision'].mean()\n",
    "    F1_score=2*precision*recall/(precision+recall)\n",
    "    print(recall,precision,F1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern 5\n",
    "\n",
    "Pattern 5 uses program variants of `DPP` and test inputs of `TC`.\n",
    "\n",
    "First load the raw results of programs' outputs `df_p5_raw`. Then compute the trigger data `p5_trigger`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_p5_raw=pd.read_pickle(\"../Data/df_p5_raw.pkl\")\n",
    "# df_p5=pd.merge(df_p5_raw,ref_generator, on=['pid', 'input_name'], suffixes=('', '_ref'),how='left')\n",
    "# df_p5['out_correct']= (df_p5['out']==df_p5['ref_out'])\n",
    "# dfa_tc_correct=df_p5[ (df_p5['sol_name'].str.contains('sol_') ) | ( df_p5['out_correct']==True)]\n",
    "\n",
    "# df_p5=(df_p5\n",
    "# [~(    \n",
    "#     (df_p5['out']=='TIME_OUT' )|\n",
    "#     (df_p5['out']=='RUN_ERROR' )|\n",
    "#     (df_p5['out']=='')\n",
    "# )\n",
    "# ])\n",
    "# df_p5['input_group']=df_p5['input_name'].apply(lambda x: x.split('_')[0]).astype(int)\n",
    "# df_p5=pd.merge(df_p5,input_valid_generator,on=['pid','input_group'],how='left')\n",
    "# df_p5['input_valid']=df_p5['input_valid'].fillna(-1)\n",
    "# df_p5['input_valid']=df_p5['input_valid'].astype(int)\n",
    "\n",
    "# p5_trigger=utils.get_trigger_df(df_p5,'cpp','tc')\n",
    "# p5_trigger['len_sol_names']=p5_trigger['sol_names'].apply(lambda x:len(x))\n",
    "# p5_trigger['final_valid']= ( (p5_trigger['input_valid'] != 0) & p5_trigger['input_valid_byref'] & p5_trigger['out_correct'] )\n",
    "# p5_trigger['total_sols_num']=p5_trigger['pid'].apply(lambda x:len(df_p5[df_p5['pid']==x].drop_duplicates(subset=['sol_name']))-1)\n",
    "# for i in range(10):\n",
    "#     column_name=f\"num{i}\"\n",
    "#     p5_trigger[column_name] = p5_trigger['sol_names'].apply(lambda x: 1 if column_name in [sol.split('_')[1] for sol in x] else 0)\n",
    "\n",
    "#  **WARNING**: The codes above in this block are time consuming. An alternative choice is to load the result directly\n",
    "p5_trigger=pd.read_pickle(\"../Data/p5_trigger.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern 5 uses diversity-driven differential testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "p5_results={}\n",
    "for i in range(2,11):\n",
    "    p5_results[i]=utils.compute_res_df(p5_trigger,i,'tc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print Pattern 5 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern 5 all results:\n",
      "k=2:   0.2577578895259077 0.7611438855412098 0.3851025611369216\n",
      "k=3:   0.2582910046371283 0.7627181431049317 0.38589906049951905\n",
      "k=4:   0.25827520429903505 0.762671485635974 0.38587545404201073\n",
      "k=5:   0.25825940396094177 0.7626248281670164 0.38585184758450236\n",
      "k=6:   0.25825940396094177 0.7626248281670164 0.38585184758450236\n",
      "k=7:   0.25825940396094177 0.7626248281670164 0.38585184758450236\n",
      "k=8:   0.25825940396094177 0.7626248281670164 0.38585184758450236\n",
      "k=9:   0.25825940396094177 0.7626248281670164 0.38585184758450236\n",
      "k=10:   0.25825940396094177 0.7626248281670164 0.38585184758450236\n"
     ]
    }
   ],
   "source": [
    "print(\"Pattern 5 all results:\")\n",
    "for i in range(2,11):\n",
    "    print(f\"k={i}:   \",end=\"\")\n",
    "    recall=p5_results[i]['TP_rate'].sum()/len_PUT\n",
    "    precision=p5_results[i]['precision'].mean()\n",
    "    F1_score=2*precision*recall/(precision+recall)\n",
    "    print(recall,precision,F1_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
